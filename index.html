<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no" />
  <title>Qwen Air Pro — Method 4 (Safe)</title>

  <script type="importmap">
    { "imports": { "@mlc-ai/web-llm": "https://esm.run/@mlc-ai/web-llm" } }
  </script>

  <style>
    /* UI: clean, mobile-friendly, lightweight */
    :root{
      --bg1:#e6efff; --bg2:#f4f7fb; --primary:#007AFF; --accent:#5856D6; --muted:#8e8e93; --card:rgba(255,255,255,0.92);
    }
    html,body{height:100%;margin:0;font-family:-apple-system,system-ui,Segoe UI,Roboto,Arial;background:linear-gradient(160deg,var(--bg1),var(--bg2));-webkit-font-smoothing:antialiased}
    .card{width:94%;max-width:470px;margin:4vh auto;height:92vh;background:var(--card);border-radius:18px;display:flex;flex-direction:column;overflow:hidden;padding-top:env(safe-area-inset-top);box-shadow:0 6px 20px rgba(6,10,18,0.06)}
    header{display:flex;align-items:center;justify-content:space-between;padding:12px 14px;border-bottom:1px solid rgba(0,0,0,0.04);background:linear-gradient(180deg, rgba(255,255,255,0.95), transparent)}
    .title{font-weight:700;color:#0b1220}
    .controls{display:flex;gap:8px;align-items:center}
    .btn{background:transparent;border:1px solid rgba(0,0,0,0.06);padding:6px 10px;border-radius:12px;font-size:13px;cursor:pointer;box-shadow:0 1px 0 rgba(255,255,255,0.6)}
    .btn--danger{color:#ff3b30;border-color:rgba(255,59,48,0.12)}
    .toggle{display:inline-flex;align-items:center;gap:8px;font-size:13px;cursor:pointer}
    .toggle input{width:40px;height:22px;appearance:none;background:#e9e9ef;border-radius:11px;position:relative;outline:none;cursor:pointer}
    .toggle input:after{content:"";position:absolute;left:3px;top:3px;width:16px;height:16px;border-radius:8px;background:#fff;box-shadow:0 1px 2px rgba(0,0,0,0.06);transition:transform 160ms ease}
    .toggle input:checked{background:linear-gradient(90deg,var(--primary),var(--accent))}
    .toggle input:checked:after{transform:translateX(18px)}
    main#chat{flex:1;overflow:auto;padding:14px;display:flex;flex-direction:column;gap:12px;background:transparent}
    .msg{max-width:78%;padding:10px 14px;border-radius:16px;word-break:break-word;font-size:15px;line-height:1.35;box-shadow:0 6px 14px rgba(11,17,24,0.04)}
    .user{align-self:flex-end;background:linear-gradient(180deg,var(--primary),#005bd8);color:#fff;border-bottom-right-radius:6px}
    .assistant{align-self:flex-start;background:#fff;color:#0b1220;border-bottom-left-radius:6px}
    .muted{font-size:12px;color:var(--muted)}
    .input-row{display:flex;padding:10px;gap:8px;border-top:1px solid rgba(0,0,0,0.04);background:linear-gradient(180deg, rgba(255,255,255,0.95), transparent)}
    input[type="text"]{flex:1;padding:12px;border-radius:18px;border:1px solid #e9e9ef;font-size:15px;background:#fff}
    button#send{background:linear-gradient(90deg,var(--primary),var(--accent));color:#fff;border:none;padding:10px 14px;border-radius:14px;cursor:pointer;box-shadow:0 6px 18px rgba(0,122,255,0.12)}
    button:disabled{opacity:0.5;cursor:not-allowed}

    /* overlay + modal (first-time only) */
    .overlay{position:absolute;inset:0;display:none;align-items:center;justify-content:center;background:rgba(8,12,20,0.12);z-index:60;padding:20px}
    .progressModal{width:88%;max-width:420px;background:var(--card);border-radius:12px;padding:14px;text-align:center;box-shadow:0 12px 40px rgba(6,10,18,0.12)}
    .progressBar{height:8px;background:#eee;border-radius:8px;overflow:hidden;margin-top:12px}
    .progressBar > i{display:block;height:100%;width:0;background:linear-gradient(90deg,var(--primary),var(--accent));transition:width 120ms linear}

    /* traits modal */
    .traitsModal{width:92%;max-width:420px;background:var(--card);border-radius:12px;padding:12px;box-shadow:0 12px 40px rgba(6,10,18,0.12)}
    .trait-chips{display:flex;flex-wrap:wrap;gap:8px;margin-top:8px}
    .chip{background:#f3f6ff;border:1px solid rgba(0,0,0,0.03);padding:6px 10px;border-radius:999px;font-size:13px}
    .traitsEditor{display:flex;flex-direction:column;gap:8px;margin-top:10px}
    .traitsEditor input{padding:8px;border-radius:8px;border:1px solid #eee}
    .modalActions{display:flex;gap:8px;justify-content:flex-end;margin-top:10px}

    /* reasoning block */
    .reasoning {background:linear-gradient(180deg,#fbfdff,#f5f8ff);border:1px solid rgba(0,0,0,0.03);padding:8px;border-radius:12px;margin-top:6px;font-size:13px;color:#0b1220}
    .reasoning .step {margin:4px 0;padding-left:6px}
    .reason-toggle{display:inline-flex;gap:8px;align-items:center;font-size:13px;cursor:pointer}

    @media (max-width:360px){
      .card{width:98%;height:94vh}
      .msg{font-size:14px}
    }
  </style>
</head>
<body>
  <div class="card" id="card">
    <!-- overlay used for first-time download ONLY -->
    <div class="overlay" id="overlay" aria-hidden="true">
      <div class="progressModal" id="progressModal" role="status" aria-live="polite">
        <div style="font-weight:600" id="overlayTitle">Preparing model…</div>
        <div class="muted" id="overlaySub">Optimized for low-memory devices</div>
        <div class="progressBar" aria-hidden="true"><i id="overlayBar"></i></div>
      </div>
    </div>

    <header>
      <div class="title">Qwen Air Pro</div>
      <div class="controls">
        <label class="toggle" title="Low Power Mode">
          <input id="lowPowerToggle" type="checkbox" />
        </label>

        <!-- Chain-of-Thought toggle -->
        <label class="toggle" title="Enable brief step-by-step reasoning">
          <input id="cotToggle" type="checkbox" />
        </label>

        <button class="btn" id="traitsBtn">Traits</button>
        <button class="btn btn--danger" id="resetBtn">Reset</button>
      </div>
    </header>

    <main id="chat" aria-live="polite" aria-atomic="false">
      <div class="msg assistant">Ready. Stateless worker strategy active.</div>
    </main>

    <div class="input-row">
      <input id="userInput" type="text" placeholder="Ask me anything..." autocomplete="off" />
      <button id="send">Send</button>
    </div>
  </div>

  <!-- Traits Editor Overlay -->
  <div class="overlay" id="traitsOverlay" aria-hidden="true">
    <div class="traitsModal" role="dialog" aria-modal="true" aria-labelledby="traitsTitle">
      <div style="display:flex;justify-content:space-between;align-items:center">
        <div id="traitsTitle" style="font-weight:700">User Traits (max 7)</div>
        <div class="muted" id="traitsCount">0/7</div>
      </div>

      <div class="trait-chips" id="traitsChips" aria-hidden="false"></div>

      <div class="traitsEditor" id="traitsEditor"></div>

      <div class="modalActions">
        <button class="btn" id="addTraitBtn">+ Add</button>
        <button class="btn" id="saveTraitsBtn">Save</button>
        <button class="btn" id="cancelTraitsBtn">Cancel</button>
      </div>

      <div class="muted" style="margin-top:8px">Low Power mode injects fewer traits and limits history to reduce memory use.</div>
    </div>
  </div>

  <script type="module">
    import * as webllm from "@mlc-ai/web-llm";

    // Config and caps (tuned for low-RAM devices)
    const MODEL_ID = "Qwen2.5-0.5B-Instruct-q4f16_1-MLC";
    const MAX_TRAITS = 7;
    const LOWPOWER_TRAITS = 2;
    const HISTORY_TURNS_NORMAL = 1;      // user+assistant
    const HISTORY_TURNS_LOW = 0;
    const REPLY_CHAR_CAP_NORMAL = 2400;  // ~600 tokens estimate
    const REPLY_CHAR_CAP_LOW = 900;      // strict low-power
    const ONDEMAND_CHAR_CAP = 700;       // cap for on-demand reasoning
    const SYSTEM_PROMPT_CHAR_CAP = 420;  // cap system prompt
    const TRAITS_KEY = 'qwen_user_traits_v1';
    const LOWPOWER_KEY = 'qwen_lowpower_v1';
    const COT_KEY = 'qwen_cot_v1';
    const MODEL_DOWNLOADED_KEY = 'qwen_model_downloaded_v1';
    const REASONING_CACHE_KEY = 'qwen_reasoning_cache_v1';
    const MAX_MESSAGES_IN_DOM = 10;      // keep DOM light
    const RECOVERY_MAX_RETRIES = 1;      // avoid repeated recovery calls

    // UI refs
    const chat = document.getElementById('chat');
    const userInput = document.getElementById('userInput');
    const sendBtn = document.getElementById('send');
    const resetBtn = document.getElementById('resetBtn');
    const overlay = document.getElementById('overlay');
    const overlayTitle = document.getElementById('overlayTitle');
    const overlaySub = document.getElementById('overlaySub');
    const overlayBar = document.getElementById('overlayBar');
    const lowPowerToggle = document.getElementById('lowPowerToggle');
    const cotToggle = document.getElementById('cotToggle');
    const traitsBtn = document.getElementById('traitsBtn');

    // modal refs
    const traitsOverlay = document.getElementById('traitsOverlay');
    const traitsEditor = document.getElementById('traitsEditor');
    const traitsChips = document.getElementById('traitsChips');
    const addTraitBtn = document.getElementById('addTraitBtn');
    const saveTraitsBtn = document.getElementById('saveTraitsBtn');
    const cancelTraitsBtn = document.getElementById('cancelTraitsBtn');
    const traitsCount = document.getElementById('traitsCount');

    // state
    let userTraits = [];
    let lowPower = false;
    let cotEnabled = false;
    let history = [];
    let engine = null; // keep for potential unload in reset
    const requestQueue = [];
    let processing = false;

    // small per-request recovery counter
    let recoveryAttempts = 0;

    // persistence helpers
    function loadTraits(){ try { const r = localStorage.getItem(TRAITS_KEY); return r ? JSON.parse(r).slice(0,MAX_TRAITS) : []; } catch { return []; } }
    function saveTraits(arr){ try { localStorage.setItem(TRAITS_KEY, JSON.stringify((arr||[]).slice(0,MAX_TRAITS))); } catch {} }
    function loadLowPower(){ try { return localStorage.getItem(LOWPOWER_KEY) === '1'; } catch { return false; } }
    function saveLowPower(v){ try { localStorage.setItem(LOWPOWER_KEY, v ? '1' : '0'); } catch {} }
    function loadCoT(){ try { return localStorage.getItem(COT_KEY) === '1'; } catch { return false; } }
    function saveCoT(v){ try { localStorage.setItem(COT_KEY, v ? '1' : '0'); } catch {} }
    function modelDownloadedFlag(){ try { return localStorage.getItem(MODEL_DOWNLOADED_KEY) === '1'; } catch { return false; } }
    function setModelDownloadedFlag(){ try { localStorage.setItem(MODEL_DOWNLOADED_KEY, '1'); } catch {} }

    // simple bounded reasoning cache stored in localStorage (small LRU-ish)
    function loadReasoningCache(){
      try {
        const raw = localStorage.getItem(REASONING_CACHE_KEY);
        if (!raw) return {};
        const obj = JSON.parse(raw);
        return obj && typeof obj === 'object' ? obj : {};
      } catch { return {}; }
    }
    function saveReasoningCache(cache){
      try {
        // keep cache small: keep last 50 entries
        const keys = Object.keys(cache || {});
        if (keys.length > 50) {
          // remove oldest by timestamp
          keys.sort((a,b) => cache[a].t - cache[b].t);
          for (let i=0;i<keys.length-50;i++) delete cache[keys[i]];
        }
        localStorage.setItem(REASONING_CACHE_KEY, JSON.stringify(cache));
      } catch {}
    }
    function getCachedReasoning(key){ const c = loadReasoningCache(); return c[key] ? c[key].v : null; }
    function setCachedReasoning(key, value){ const c = loadReasoningCache(); c[key] = { v: value, t: Date.now() }; saveReasoningCache(c); }

    // helpers
    function appendMessage(role, text){
      // limit DOM message growth: remove the oldest while keeping within limit
      while (chat.children.length >= MAX_MESSAGES_IN_DOM) {
        chat.removeChild(chat.firstChild);
      }
      const d = document.createElement('div');
      d.className = 'msg ' + (role === 'user' ? 'user' : 'assistant');
      d.textContent = text;
      chat.appendChild(d);
      requestAnimationFrame(() => { chat.scrollTop = chat.scrollHeight; });
      return d;
    }

    function clampString(s, maxChars){
      if(!s) return '';
      if(s.length <= maxChars) return s;
      return s.slice(0, maxChars - 3) + '...';
    }

    // overlay controls (first-time only) — throttle updates to reduce DOM churn
    let lastOverlayProgress = -1;
    function showOverlay(title='Preparing model…', sub='Optimizing for low-memory', progress=0){
      const p = Math.max(0, Math.min(1, progress));
      if (Math.abs(p - lastOverlayProgress) < 0.02 && overlay.style.display === 'flex') {
        overlayTitle.textContent = title;
        overlaySub.textContent = sub;
        return;
      }
      lastOverlayProgress = p;
      overlayTitle.textContent = title;
      overlaySub.textContent = sub;
      overlayBar.style.width = `${Math.round(p * 100)}%`;
      overlay.style.display = 'flex';
      overlay.setAttribute('aria-hidden', 'false');
    }
    function hideOverlay(){ overlay.style.display = 'none'; overlay.setAttribute('aria-hidden', 'true'); overlayBar.style.width = '0%'; lastOverlayProgress = -1; }

    // Engine create with progress callback — sets downloaded flag on real download
    async function createEngineWithProgress() {
      const alreadyDownloaded = modelDownloadedFlag();
      let downloadObserved = false;

      const eng = await webllm.CreateMLCEngine(MODEL_ID, {
        initProgressCallback: (report) => {
          const p = Math.max(0, Math.min(1, (report && report.progress) || 0));
          const text = (report && report.text) || '';

          if (!alreadyDownloaded) {
            if (p < 1) {
              downloadObserved = true;
              showOverlay(text || 'Downloading model…', 'This happens only once on this device', p);
            } else {
              if (downloadObserved) setModelDownloadedFlag();
              hideOverlay();
            }
          }
        }
      });

      return eng;
    }

    // build compact system prompt that includes probabilistic reasoning + CoT policy
    // IMPORTANT: require Answer: first then optional steps then Certainty:. This reduces certainty-only replies.
    function buildSystemPrompt(){
      const traits = lowPower ? userTraits.slice(0, LOWPOWER_TRAITS) : userTraits.slice(0, MAX_TRAITS);
      const compact = traits.map(t => t.replace(/\s+/g, ' ').trim()).filter(Boolean).join(' | ');
      const prob = "Treat outputs as probabilistic predictions; avoid overconfidence. Always include the final answer prefixed with 'Answer:' (single-line). Optionally append 'Certainty: [High|Medium|Low]' after the answer.";
      let cotInstr = "";
      if (cotEnabled && !lowPower) {
        cotInstr = "When enabled, you may include up to 3 concise numbered reasoning steps BEFORE the final 'Answer:'. Keep steps short.";
      } else if (cotEnabled && lowPower) {
        cotInstr = "CoT is enabled but device is in Low Power: provide a single concise step before 'Answer:'.";
      } else {
        cotInstr = "Do not expose internal chain-of-thought; provide a concise direct answer (use 'Answer:'), and optionally a short 'Certainty:' tag.";
      }

      const base = lowPower ? "Concise assistant. Keep replies extremely short." : "Concise assistant. Keep replies short.";
      const systemRaw = compact ? `${base} User: ${compact}. ${prob} ${cotInstr}` : `${base} ${prob} ${cotInstr}`;
      return clampString(systemRaw, SYSTEM_PROMPT_CHAR_CAP);
    }

    function buildMessages(userText){
      const system = buildSystemPrompt();
      const historyTurns = lowPower ? HISTORY_TURNS_LOW : HISTORY_TURNS_NORMAL;
      const turnsToKeep = historyTurns * 2;
      const recent = history.slice(-turnsToKeep).map(m => ({ role: m.role === 'assistant' ? 'assistant' : 'user', content: m.content }));
      return [{ role: 'system', content: system }, ...recent, { role: 'user', content: userText }];
    }

    // parse reasoning & answer from model reply if structured as steps + "Answer:"
    function extractReasoningAndAnswer(fullText) {
      if (!fullText) return { steps: [], answer: '' };
      // look for "Answer:" token (case-insensitive)
      const answerMatch = fullText.match(/Answer\s*:\s*([\s\S]*)$/i);
      if (answerMatch) {
        const answer = answerMatch[1].trim();
        const reasoningPart = fullText.slice(0, answerMatch.index).trim();
        const steps = reasoningPart ? reasoningPart.split(/\r?\n/).map(s => s.trim()).filter(Boolean) : [];
        return { steps, answer };
      }
      // fallback: try to detect "Certainty:" suffix
      const certMatch = fullText.match(/(.*)\nCertainty\s*:\s*(High|Medium|Low)/i);
      if (certMatch) {
        const reasoningAndAnswer = certMatch[1].trim();
        return { steps: [], answer: reasoningAndAnswer };
      }
      return { steps: [], answer: fullText.trim() };
    }

    // small helper to detect certainty-only or trivial outputs
    function isCertaintyOnly(text) {
      if (!text) return true;
      const t = text.trim();
      // single words like High, Medium, Low (case-insensitive)
      if (/^(high|medium|low)$/i.test(t)) return true;
      // single-letter responses or extremely short fragments
      if (t.length <= 3 && /^[A-Za-z]{1,3}$/.test(t)) return true;
      return false;
    }

    // UI: render assistant reply with optional on-demand reasoning button
    function renderAssistantReply(fullReply, userText) {
      const { steps, answer } = extractReasoningAndAnswer(fullReply);

      const assistantDiv = document.createElement('div');
      assistantDiv.className = 'msg assistant';
      assistantDiv.textContent = answer || fullReply || '…';
      chat.appendChild(assistantDiv);

      function createReasoningUI(stepsArr) {
        const wrapper = document.createElement('div');
        wrapper.style.display = 'flex';
        wrapper.style.flexDirection = 'column';
        wrapper.style.alignItems = 'flex-start';
        wrapper.style.maxWidth = '78%';

        const toggle = document.createElement('button');
        toggle.className = 'btn';
        toggle.textContent = 'Show reasoning';
        toggle.style.marginTop = '6px';
        toggle.style.padding = '6px 8px';
        toggle.style.fontSize = '13px';

        const reasoningBox = document.createElement('div');
        reasoningBox.className = 'reasoning';
        reasoningBox.style.display = 'none';

        stepsArr.forEach((s) => {
          const stepEl = document.createElement('div');
          stepEl.className = 'step';
          stepEl.textContent = s;
          reasoningBox.appendChild(stepEl);
        });

        toggle.addEventListener('click', () => {
          const visible = reasoningBox.style.display !== 'none';
          reasoningBox.style.display = visible ? 'none' : 'block';
          toggle.textContent = visible ? 'Show reasoning' : 'Hide reasoning';
        });

        wrapper.appendChild(toggle);
        wrapper.appendChild(reasoningBox);
        chat.appendChild(wrapper);
      }

      if (steps && steps.length > 0) {
        createReasoningUI(steps);
      } else {
        const explainBtn = document.createElement('button');
        explainBtn.className = 'btn';
        explainBtn.textContent = 'Explain';
        explainBtn.style.marginTop = '6px';
        explainBtn.style.padding = '6px 8px';
        explainBtn.style.fontSize = '13px';

        explainBtn.addEventListener('click', async () => {
          explainBtn.disabled = true;
          const key = `k:${hashString((userText || '') + '||' + (answer || fullReply || ''))}`;
          const cached = getCachedReasoning(key);
          if (cached) {
            createReasoningUI(cached);
            explainBtn.disabled = false;
            return;
          }

          const ONDEMAND_STEP_LIMIT = lowPower ? 1 : 2;
          const perStepChar = 120;
          const sys = clampString(`Produce up to ${ONDEMAND_STEP_LIMIT} concise numbered reasoning steps (each <= ${perStepChar} chars). Then a single-line 'Answer:' and 'Certainty: [High|Medium|Low]'. No extra commentary.`, 380);
          const prompt = `Question: ${userText || '[unknown]'}\nAnswer: ${answer || fullReply || '[unknown]'}\nProvide only the concise reasoning steps and final Answer/Certainty.`;

          const fetchingBox = document.createElement('div');
          fetchingBox.className = 'reasoning';
          fetchingBox.style.display = 'block';
          fetchingBox.textContent = 'Fetching explanation…';
          chat.appendChild(fetchingBox);
          chat.scrollTop = chat.scrollHeight;

          let eng = null;
          try {
            eng = await createEngineWithProgress();
            const messages = [{ role: 'system', content: sys }, { role: 'user', content: prompt }];
            const chunks = await eng.chat.completions.create({ messages, stream: true });
            let reasoningText = '';
            for await (const chunk of chunks) {
              const delta = chunk?.choices?.[0]?.delta?.content || '';
              if (delta) {
                reasoningText += delta;
                if (reasoningText.length > ONDEMAND_CHAR_CAP) {
                  reasoningText = reasoningText.slice(0, ONDEMAND_CHAR_CAP) + '\n\n[truncated]';
                  break;
                }
              }
            }
            try { await eng.unload(); } catch (e) {}
            eng = null;

            fetchingBox.remove();

            const parsed = extractReasoningAndAnswer(reasoningText);
            const stepsOut = parsed.steps && parsed.steps.length ? parsed.steps.slice(0, ONDEMAND_STEP_LIMIT) : [parsed.answer].filter(Boolean);
            if (stepsOut.length === 0) {
              appendMessage('assistant', 'No concise reasoning could be produced.');
            } else {
              setCachedReasoning(key, stepsOut);
              createReasoningUI(stepsOut);
            }
          } catch (err) {
            console.error('Reasoning fetch error', err);
            if (fetchingBox && fetchingBox.parentNode) fetchingBox.textContent = 'Failed to fetch explanation.';
            setTimeout(() => { try { if (fetchingBox && fetchingBox.parentNode) fetchingBox.remove(); } catch(e){} }, 1800);
            try { if (eng) await eng.unload(); } catch(e){}
            eng = null;
          } finally {
            explainBtn.disabled = false;
            requestAnimationFrame(() => { chat.scrollTop = chat.scrollHeight; });
          }
        });

        chat.appendChild(explainBtn);
      }

      requestAnimationFrame(() => { chat.scrollTop = chat.scrollHeight; });
    }

    // small non-cryptographic hash for cache keys (fast)
    function hashString(s) {
      let h = 2166136261 >>> 0;
      for (let i = 0; i < s.length; i++) {
        h ^= s.charCodeAt(i);
        h = Math.imul(h, 16777619) >>> 0;
      }
      return h.toString(16);
    }

    // Core queue processing
    async function processQueue(){
      if (processing) return;
      processing = true;
      while (requestQueue.length) {
        const req = requestQueue.shift();
        await handleSingleRequest(req.userText);
        await new Promise(resolve => setTimeout(resolve, 120));
      }
      processing = false;
    }

    // Recovery helper — ask a strict single-line answer if the first reply was only a certainty
    async function recoveryDirectAnswer(userText) {
      try {
        const eng = await createEngineWithProgress();
        const sys = "Concise assistant. Provide a single-line direct answer to the user's question. Do NOT include 'Certainty' or steps — just the answer.";
        const messages = [{ role: 'system', content: sys }, { role: 'user', content: userText }];
        const chunks = await eng.chat.completions.create({ messages, stream: true });
        let text = '';
        for await (const chunk of chunks) {
          const delta = chunk?.choices?.[0]?.delta?.content || '';
          if (delta) {
            text += delta;
            if (text.length > (lowPower ? REPLY_CHAR_CAP_LOW : REPLY_CHAR_CAP_NORMAL)) {
              text = text.slice(0, lowPower ? REPLY_CHAR_CAP_LOW : REPLY_CHAR_CAP_NORMAL) + '\n\n[truncated]';
              break;
            }
          }
        }
        try { await eng.unload(); } catch(e) {}
        return text.trim();
      } catch (err) {
        console.error('Recovery fetch failed', err);
        return null;
      }
    }

    // Handle single request implementing Method 4 and CoT constraints
    async function handleSingleRequest(userText) {
      recoveryAttempts = 0;
      const replyCharCap = lowPower ? REPLY_CHAR_CAP_LOW : REPLY_CHAR_CAP_NORMAL;
      const messages = buildMessages(userText);

      const placeholder = appendMessage('assistant', '…');

      const alreadyDownloaded = modelDownloadedFlag();
      if (!alreadyDownloaded) {
        showOverlay('Preparing engine…', 'First-time model download may take longer', 0);
        await new Promise(requestAnimationFrame);
      } else {
        await new Promise(requestAnimationFrame);
      }

      sendBtn.disabled = true;
      let localEngine = null;

      try {
        localEngine = await createEngineWithProgress();
        const chunks = await localEngine.chat.completions.create({ messages, stream: true });

        let fullReply = '';
        for await (const chunk of chunks) {
          const delta = chunk?.choices?.[0]?.delta?.content || '';
          if (delta) {
            fullReply += delta;
            placeholder.textContent = fullReply;
            if (fullReply.length > replyCharCap) {
              fullReply = fullReply.slice(0, replyCharCap) + '\n\n[truncated to fit device limits]';
              placeholder.textContent = fullReply;
              break;
            }
            if (fullReply.length % 200 === 0) await new Promise(requestAnimationFrame);
          }
        }

        try { await localEngine.unload(); } catch(e) {}
        localEngine = null;

        // if the model returned only a certainty or an extremely short fragment, try a quick recovery call once
        if (isCertaintyOnly(fullReply) && recoveryAttempts < RECOVERY_MAX_RETRIES) {
          recoveryAttempts++;
          placeholder.textContent = '[received tag only — fetching concise answer…]';
          const recovered = await recoveryDirectAnswer(userText);
          if (recovered) {
            placeholder.remove();
            renderAssistantReply(recovered, userText);
            history.push({ role: 'user', content: userText }, { role: 'assistant', content: recovered });
            const maxEntries = (lowPower ? HISTORY_TURNS_LOW : HISTORY_TURNS_NORMAL) * 2;
            if (maxEntries > 0 && history.length > maxEntries) history = history.slice(-maxEntries);
            if (maxEntries === 0) history = [];
            hideOverlay();
            return;
          }
          // if recovery failed, fall back to showing the original (certainty) reply below
        }

        placeholder.remove();
        renderAssistantReply(fullReply, userText);

        history.push({ role: 'user', content: userText }, { role: 'assistant', content: fullReply });
        const maxEntries = (lowPower ? HISTORY_TURNS_LOW : HISTORY_TURNS_NORMAL) * 2;
        if (maxEntries > 0 && history.length > maxEntries) history = history.slice(-maxEntries);
        if (maxEntries === 0) history = [];

        hideOverlay();
      } catch (err) {
        console.error('Inference error', err);
        placeholder.remove();
        appendMessage('assistant', 'I had a memory spike or connection error. Try again in a moment.');
        try { if (localEngine) await localEngine.unload(); } catch(e){}
        localEngine = null;
        hideOverlay();
      } finally {
        sendBtn.disabled = false;
      }
    }

    // queue request (adds to single-run queue)
    function queueRequest(userText){
      if (!userText || !userText.trim()) return;
      appendMessage('user', userText);
      requestQueue.push({ userText });
      processQueue();
    }

    // UI wiring
    sendBtn.addEventListener('click', () => {
      const txt = userInput.value.trim();
      if (!txt) return;
      userInput.value = '';
      queueRequest(txt);
    });
    userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') { e.preventDefault(); sendBtn.click(); } });

    // Reset
    resetBtn.addEventListener('click', async () => {
      history = [];
      chat.innerHTML = '<div class="msg assistant">Memory purged. Ready.</div>';
      requestQueue.length = 0;
      try { if (engine) await engine.unload(); } catch(e) {}
      engine = null;
    });

    // Low-power toggle wiring
    lowPower = loadLowPower();
    lowPowerToggle.checked = lowPower;
    lowPowerToggle.addEventListener('change', (e) => {
      lowPower = !!e.target.checked;
      saveLowPower(lowPower);
      if (lowPower && cotEnabled) {
        cotEnabled = false;
        cotToggle.checked = false;
        saveCoT(false);
        appendMessage('assistant', 'Low Power enabled — reasoning limited to preserve memory.');
      } else {
        appendMessage('assistant', lowPower ? 'Low Power enabled.' : 'Low Power disabled.');
      }
    });

    // CoT toggle wiring
    cotEnabled = loadCoT();
    cotToggle.checked = cotEnabled;
    if (lowPower && cotEnabled) { cotEnabled = false; cotToggle.checked = false; saveCoT(false); }
    cotToggle.addEventListener('change', (e) => {
      const requested = !!e.target.checked;
      if (lowPower && requested) {
        cotToggle.checked = false;
        cotEnabled = false;
        saveCoT(false);
        appendMessage('assistant', 'Cannot enable detailed reasoning while Low Power is ON.');
        return;
      }
      cotEnabled = requested;
      saveCoT(cotEnabled);
      appendMessage('assistant', cotEnabled ? 'Reasoning enabled.' : 'Reasoning disabled.');
    });

    // Traits editor wiring
    function openTraits(){ renderTraitsModal(); traitsOverlay.style.display = 'flex'; traitsOverlay.setAttribute('aria-hidden','false'); }
    function closeTraits(){ traitsOverlay.style.display = 'none'; traitsOverlay.setAttribute('aria-hidden','true'); }

    function renderTraitsModal(){
      traitsEditor.innerHTML = '';
      traitsChips.innerHTML = '';
      userTraits.forEach((t, idx) => {
        const chip = document.createElement('div'); chip.className = 'chip'; chip.textContent = t; traitsChips.appendChild(chip);
        const row = document.createElement('div');
        row.style.display = 'flex'; row.style.gap = '8px'; row.style.alignItems = 'center';
        const input = document.createElement('input'); input.value = t; input.placeholder = `Trait ${idx+1}`;
        input.addEventListener('input', () => userTraits[idx] = input.value);
        const rm = document.createElement('button'); rm.className = 'btn'; rm.textContent = 'Remove';
        rm.addEventListener('click', () => { userTraits.splice(idx,1); renderTraitsModal(); });
        row.appendChild(input); row.appendChild(rm);
        traitsEditor.appendChild(row);
      });
      traitsCount.textContent = `${userTraits.length}/${MAX_TRAITS}`;
    }

    addTraitBtn.addEventListener('click', () => {
      if (userTraits.length >= MAX_TRAITS) return;
      userTraits.push('');
      renderTraitsModal();
    });
    saveTraitsBtn.addEventListener('click', () => {
      userTraits = userTraits.map(s => (s || '').trim()).filter(Boolean).slice(0, MAX_TRAITS);
      saveTraits(userTraits);
      closeTraits();
      appendMessage('assistant', 'Traits saved.');
    });
    cancelTraitsBtn.addEventListener('click', () => closeTraits());
    traitsBtn.addEventListener('click', () => openTraits());

    // initial load: use small default trait set for low memory
    userTraits = loadTraits();
    if (!userTraits || !userTraits.length) {
      userTraits = ['Concise','English'];
      saveTraits(userTraits);
    }
    lowPower = loadLowPower();
    cotEnabled = loadCoT();
    if (lowPower && cotEnabled) { cotEnabled = false; cotToggle.checked = false; saveCoT(false); }

    // focus input
    userInput.focus();
  </script>
</body>
</html>
