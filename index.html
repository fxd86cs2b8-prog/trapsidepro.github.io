<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no" />
  <title>Qwen Air Pro — Low Power Primary</title>

  <script type="importmap">
    { "imports": { "@mlc-ai/web-llm": "https://esm.run/@mlc-ai/web-llm" } }
  </script>

  <style>
    /* UI: clean, mobile-friendly, lightweight */
    :root{
      --bg1:#e6efff; --bg2:#f4f7fb; --primary:#007AFF; --accent:#5856D6; --muted:#8e8e93; --card:rgba(255,255,255,0.92);
    }
    html,body{height:100%;margin:0;font-family:-apple-system,system-ui,Segoe UI,Roboto,Arial;background:linear-gradient(160deg,var(--bg1),var(--bg2));-webkit-font-smoothing:antialiased}
    .card{width:94%;max-width:470px;margin:4vh auto;height:92vh;background:var(--card);border-radius:18px;display:flex;flex-direction:column;overflow:hidden;padding-top:env(safe-area-inset-top);box-shadow:0 6px 20px rgba(6,10,18,0.06)}
    header{display:flex;align-items:center;justify-content:space-between;padding:12px 14px;border-bottom:1px solid rgba(0,0,0,0.04);background:linear-gradient(180deg, rgba(255,255,255,0.95), transparent)}
    .title{font-weight:700;color:#0b1220}
    .controls{display:flex;gap:8px;align-items:center}
    .btn{background:transparent;border:1px solid rgba(0,0,0,0.06);padding:6px 10px;border-radius:12px;font-size:13px;cursor:pointer;box-shadow:0 1px 0 rgba(255,255,255,0.6)}
    .btn--danger{color:#ff3b30;border-color:rgba(255,59,48,0.12)}
    .toggle{display:inline-flex;align-items:center;gap:8px;font-size:13px;cursor:pointer}
    .toggle input{width:40px;height:22px;appearance:none;background:#e9e9ef;border-radius:11px;position:relative;outline:none;cursor:pointer}
    .toggle input:after{content:"";position:absolute;left:3px;top:3px;width:16px;height:16px;border-radius:8px;background:#fff;box-shadow:0 1px 2px rgba(0,0,0,0.06);transition:transform 160ms ease}
    .toggle input:checked{background:linear-gradient(90deg,var(--primary),var(--accent))}
    .toggle input:checked:after{transform:translateX(18px)}
    main#chat{flex:1;overflow:auto;padding:14px;display:flex;flex-direction:column;gap:12px;background:transparent}
    .msg{max-width:78%;padding:10px 14px;border-radius:16px;word-break:break-word;font-size:15px;line-height:1.35;box-shadow:0 6px 14px rgba(11,17,24,0.04)}
    .user{align-self:flex-end;background:linear-gradient(180deg,var(--primary),#005bd8);color:#fff;border-bottom-right-radius:6px}
    .assistant{align-self:flex-start;background:#fff;color:#0b1220;border-bottom-left-radius:6px}
    .muted{font-size:12px;color:var(--muted)}
    .input-row{display:flex;padding:10px;gap:8px;border-top:1px solid rgba(0,0,0,0.04);background:linear-gradient(180deg, rgba(255,255,255,0.95), transparent)}
    input[type="text"]{flex:1;padding:12px;border-radius:18px;border:1px solid #e9e9ef;font-size:15px;background:#fff}
    button#send{background:linear-gradient(90deg,var(--primary),var(--accent));color:#fff;border:none;padding:10px 14px;border-radius:14px;cursor:pointer;box-shadow:0 6px 18px rgba(0,122,255,0.12)}
    button:disabled{opacity:0.5;cursor:not-allowed}

    /* overlay + modal (first-time only) */
    .overlay{position:absolute;inset:0;display:none;align-items:center;justify-content:center;background:rgba(8,12,20,0.12);z-index:60;padding:20px}
    .progressModal{width:88%;max-width:420px;background:var(--card);border-radius:12px;padding:14px;text-align:center;box-shadow:0 12px 40px rgba(6,10,18,0.12)}
    .progressBar{height:8px;background:#eee;border-radius:8px;overflow:hidden;margin-top:12px}
    .progressBar > i{display:block;height:100%;width:0;background:linear-gradient(90deg,var(--primary),var(--accent));transition:width 120ms linear}

    /* traits modal */
    .traitsModal{width:92%;max-width:420px;background:var(--card);border-radius:12px;padding:12px;box-shadow:0 12px 40px rgba(6,10,18,0.12)}
    .trait-chips{display:flex;flex-wrap:wrap;gap:8px;margin-top:8px}
    .chip{background:#f3f6ff;border:1px solid rgba(0,0,0,0.03);padding:6px 10px;border-radius:999px;font-size:13px}
    .traitsEditor{display:flex;flex-direction:column;gap:8px;margin-top:10px}
    .traitsEditor input{padding:8px;border-radius:8px;border:1px solid #eee}
    .modalActions{display:flex;gap:8px;justify-content:flex-end;margin-top:10px}

    /* thinking & reveal */
    .thinking {font-style:italic;color:var(--muted);padding:8px 12px;border-radius:12px;background:transparent;border:1px dashed rgba(0,0,0,0.04);max-width:78%}
    .fade-in { animation: fadeIn 360ms ease; }
    @keyframes fadeIn { from { opacity: 0; transform: translateY(4px);} to { opacity: 1; transform: translateY(0); } }

    @media (max-width:360px){
      .card{width:98%;height:94vh}
      .msg{font-size:14px}
    }
  </style>
</head>
<body>
  <div class="card" id="card">
    <!-- overlay used for first-time download ONLY -->
    <div class="overlay" id="overlay" aria-hidden="true">
      <div class="progressModal" id="progressModal" role="status" aria-live="polite">
        <div style="font-weight:600" id="overlayTitle">Preparing model…</div>
        <div class="muted" id="overlaySub">Optimized for low-memory devices</div>
        <div class="progressBar" aria-hidden="true"><i id="overlayBar"></i></div>
      </div>
    </div>

    <header>
      <div class="title">Qwen Air Pro</div>
      <div class="controls">
        <!-- Low Power toggle (kept, default ON) -->
        <label class="toggle" title="Low Power Mode">
          <input id="lowPowerToggle" type="checkbox" />
        </label>

        <button class="btn" id="traitsBtn">Traits</button>
        <button class="btn btn--danger" id="resetBtn">Reset</button>
      </div>
    </header>

    <main id="chat" aria-live="polite" aria-atomic="false">
      <div class="msg assistant">Ready. Low Power mode is primary.</div>
    </main>

    <div class="input-row">
      <input id="userInput" type="text" placeholder="Ask me anything..." autocomplete="off" />
      <button id="send">Send</button>
    </div>
  </div>

  <!-- Traits Editor Overlay -->
  <div class="overlay" id="traitsOverlay" aria-hidden="true">
    <div class="traitsModal" role="dialog" aria-modal="true" aria-labelledby="traitsTitle">
      <div style="display:flex;justify-content:space-between;align-items:center">
        <div id="traitsTitle" style="font-weight:700">User Traits (max 7)</div>
        <div class="muted" id="traitsCount">0/7</div>
      </div>

      <div class="trait-chips" id="traitsChips" aria-hidden="false"></div>

      <div class="traitsEditor" id="traitsEditor"></div>

      <div class="modalActions">
        <button class="btn" id="addTraitBtn">+ Add</button>
        <button class="btn" id="saveTraitsBtn">Save</button>
        <button class="btn" id="cancelTraitsBtn">Cancel</button>
      </div>

      <div class="muted" style="margin-top:8px">Low Power mode injects fewer traits and limits history to reduce memory use.</div>
    </div>
  </div>

  <script type="module">
    import * as webllm from "@mlc-ai/web-llm";

    // Config and caps (tuned for iPhone 7 / low RAM)
    const MODEL_ID = "Qwen2.5-0.5B-Instruct-q4f16_1-MLC";
    const MAX_TRAITS = 7;
    const LOWPOWER_TRAITS = 2;
    const HISTORY_TURNS_LOW = 0;         // keep history off in low-power primary
    const REPLY_CHAR_CAP_LOW = 500;      // PER YOUR REQUEST: 400-500; set to 500
    const SYSTEM_PROMPT_CHAR_CAP = 420;
    const TRAITS_KEY = 'qwen_user_traits_v1';
    const LOWPOWER_KEY = 'qwen_lowpower_v1';
    const MODEL_DOWNLOADED_KEY = 'qwen_model_downloaded_v1';
    const REASONING_CACHE_KEY = 'qwen_reasoning_cache_v1';
    const MAX_MESSAGES_IN_DOM = 6;       // keep DOM small (4-6 recommended; using 6)
    const MAX_RESET_RETRIES = 2;         // attempts to reset model on memory spike

    // UI refs
    const chat = document.getElementById('chat');
    const userInput = document.getElementById('userInput');
    const sendBtn = document.getElementById('send');
    const resetBtn = document.getElementById('resetBtn');
    const overlay = document.getElementById('overlay');
    const overlayTitle = document.getElementById('overlayTitle');
    const overlaySub = document.getElementById('overlaySub');
    const overlayBar = document.getElementById('overlayBar');
    const lowPowerToggle = document.getElementById('lowPowerToggle');
    const traitsBtn = document.getElementById('traitsBtn');

    // modal refs
    const traitsOverlay = document.getElementById('traitsOverlay');
    const traitsEditor = document.getElementById('traitsEditor');
    const traitsChips = document.getElementById('traitsChips');
    const addTraitBtn = document.getElementById('addTraitBtn');
    const saveTraitsBtn = document.getElementById('saveTraitsBtn');
    const cancelTraitsBtn = document.getElementById('cancelTraitsBtn');
    const traitsCount = document.getElementById('traitsCount');

    // state
    let userTraits = [];
    function loadLowPowerRaw(){ try { return localStorage.getItem(LOWPOWER_KEY); } catch { return null; } }
    function loadLowPower(){ try { return localStorage.getItem(LOWPOWER_KEY) === '1'; } catch { return false; } }
    function saveLowPower(v){ try { localStorage.setItem(LOWPOWER_KEY, v ? '1' : '0'); } catch {} }

    let lowPower = true; // will be set in init
    let history = [];
    let engine = null; // global ref to allow force-unload in reset
    const requestQueue = [];
    let processing = false;

    // persistence helpers (traits + small cache)
    function loadTraits(){ try { const r = localStorage.getItem(TRAITS_KEY); return r ? JSON.parse(r).slice(0,MAX_TRAITS) : []; } catch { return []; } }
    function saveTraits(arr){ try { localStorage.setItem(TRAITS_KEY, JSON.stringify((arr||[]).slice(0,MAX_TRAITS))); } catch {} }
    function modelDownloadedFlag(){ try { return localStorage.getItem(MODEL_DOWNLOADED_KEY) === '1'; } catch { return false; } }
    function setModelDownloadedFlag(){ try { localStorage.setItem(MODEL_DOWNLOADED_KEY, '1'); } catch {} }

    function loadReasoningCache(){
      try {
        const raw = localStorage.getItem(REASONING_CACHE_KEY);
        if (!raw) return {};
        const obj = JSON.parse(raw);
        return obj && typeof obj === 'object' ? obj : {};
      } catch { return {}; }
    }
    function saveReasoningCache(cache){
      try {
        const keys = Object.keys(cache || {});
        if (keys.length > 50) {
          keys.sort((a,b) => cache[a].t - cache[b].t);
          for (let i=0;i<keys.length-50;i++) delete cache[keys[i]];
        }
        localStorage.setItem(REASONING_CACHE_KEY, JSON.stringify(cache));
      } catch {}
    }

    // helpers
    function appendMessage(role, text, opts = {}) {
      // limit DOM message growth: remove the oldest while keeping within limit
      try {
        while (chat.children.length >= MAX_MESSAGES_IN_DOM) {
          chat.removeChild(chat.firstChild);
        }
      } catch (e) { /* ignore DOM prune errors */ }

      const d = document.createElement('div');
      d.className = (opts.className ? opts.className + ' ' : '') + 'msg ' + (role === 'user' ? 'user' : 'assistant');
      d.textContent = text;
      if (opts.aria) d.setAttribute('aria-live', opts.aria);
      chat.appendChild(d);
      requestAnimationFrame(() => { chat.scrollTop = chat.scrollHeight; });
      return d;
    }

    function clampString(s, maxChars){
      if(!s) return '';
      if(s.length <= maxChars) return s;
      return s.slice(0, maxChars - 3) + '...';
    }

    // overlay controls (throttled)
    let lastOverlayProgress = -1;
    function showOverlay(title='Preparing model…', sub='Optimizing for low-memory', progress=0){
      const p = Math.max(0, Math.min(1, progress));
      if (Math.abs(p - lastOverlayProgress) < 0.02 && overlay.style.display === 'flex') {
        overlayTitle.textContent = title;
        overlaySub.textContent = sub;
        return;
      }
      lastOverlayProgress = p;
      overlayTitle.textContent = title;
      overlaySub.textContent = sub;
      overlayBar.style.width = `${Math.round(p * 100)}%`;
      overlay.style.display = 'flex';
      overlay.setAttribute('aria-hidden', 'false');
    }
    function hideOverlay(){ overlay.style.display = 'none'; overlay.setAttribute('aria-hidden', 'true'); overlayBar.style.width = '0%'; lastOverlayProgress = -1; }

    // Engine create with progress callback — sets downloaded flag on real download
    async function createEngineWithProgress() {
      const alreadyDownloaded = modelDownloadedFlag();
      let downloadObserved = false;

      const eng = await webllm.CreateMLCEngine(MODEL_ID, {
        initProgressCallback: (report) => {
          const p = Math.max(0, Math.min(1, (report && report.progress) || 0));
          const text = (report && report.text) || '';

          if (!alreadyDownloaded) {
            if (p < 1) {
              downloadObserved = true;
              showOverlay(text || 'Downloading model…', 'This happens only once on this device', p);
            } else {
              if (downloadObserved) setModelDownloadedFlag();
              hideOverlay();
            }
          }
        }
      });

      return eng;
    }

    // system prompt tuned for low-power only
    function buildSystemPrompt(){
      const traits = userTraits.slice(0, LOWPOWER_TRAITS);
      const compact = traits.map(t => t.replace(/\s+/g, ' ').trim()).filter(Boolean).join(' | ');
      const prob = "Treat outputs as probabilistic predictions; avoid overconfidence. Provide a single-line 'Answer:' as the final output. Keep replies extremely short.";
      const base = "Concise assistant. Keep replies extremely short.";
      const systemRaw = compact ? `${base} User: ${compact}. ${prob}` : `${base} ${prob}`;
      return clampString(systemRaw, SYSTEM_PROMPT_CHAR_CAP);
    }

    function buildMessages(userText){
      const system = buildSystemPrompt();
      // low power uses no history
      const recent = [];
      return [{ role: 'system', content: system }, ...recent, { role: 'user', content: userText }];
    }

    // parse "Answer:" style outputs
    function extractAnswer(fullText) {
      if (!fullText) return '';
      const answerMatch = fullText.match(/Answer\s*:\s*([\s\S]*)$/i);
      if (answerMatch) return answerMatch[1].trim();
      // fallback to full text
      return fullText.trim();
    }

    // small helper to detect trivial outputs (e.g., certainty-only)
    function isTrivial(text) {
      if (!text) return true;
      const t = text.trim();
      if (/^(high|medium|low)$/i.test(t)) return true;
      if (t.length <= 3 && /^[A-Za-z]{1,3}$/.test(t)) return true;
      return false;
    }

    // aggressive reset and retry (unload, prune DOM, probe, retry)
    async function aggressiveResetAndRetry(originalUserText) {
      appendMessage('assistant', 'Trying to refresh my mind...');
      sendBtn.disabled = true;

      // clear queued requests; we'll requeue original if reset succeeds
      requestQueue.length = 0;

      // prune DOM aggressively (keep last 1-2 messages)
      try {
        while (chat.children.length > 2) chat.removeChild(chat.firstChild);
      } catch (e) { console.warn('DOM prune failed', e); }

      // unload any existing engine
      try {
        if (engine && typeof engine.unload === 'function') {
          await engine.unload();
        }
      } catch (e) { console.warn('error unloading engine during aggressive reset', e); }
      engine = null;

      // small pause to allow GC to run
      await new Promise(resolve => setTimeout(resolve, 600));

      // clear transient caches that may hold big data
      try { localStorage.removeItem(REASONING_CACHE_KEY); } catch(e){}

      // probe create+unload
      try {
        const probe = await createEngineWithProgress();
        try { if (probe && typeof probe.unload === 'function') await probe.unload(); } catch(e) { console.warn('probe unload failed', e); }
        appendMessage('assistant', 'I refreshed successfully. Retrying your question...');
        await new Promise(resolve => setTimeout(resolve, 300));
        if (originalUserText && originalUserText.trim()) {
          // re-run original question once
          await handleSingleRequest(originalUserText, /*retriesLeft*/ 0);
        }
        sendBtn.disabled = false;
        return true;
      } catch (probeErr) {
        console.warn('Probe create failed', probeErr);
        appendMessage('assistant', 'I could not refresh fully. Performing a quick page refresh to free memory...');
        setTimeout(() => {
          try { window.location.reload(); } catch (reloadErr) {
            console.error('reload failed', reloadErr);
            appendMessage('assistant', 'Automatic reload failed. Please manually refresh the page.');
            sendBtn.disabled = false;
          }
        }, 700);
        return false;
      }
    }

    // core request processing (with "thinking..." reveal delay)
    async function handleSingleRequest(userText, retriesLeft = MAX_RESET_RETRIES) {
      const replyCharCap = REPLY_CHAR_CAP_LOW;
      const messages = buildMessages(userText);

      // create a "thinking..." placeholder (visible to user immediately)
      const thinkingEl = appendMessage('assistant', 'Thinking...', { className: 'thinking' });

      // show overlay for first-time download
      const alreadyDownloaded = modelDownloadedFlag();
      if (!alreadyDownloaded) {
        showOverlay('Preparing engine…', 'First-time model download may take longer', 0);
        await new Promise(requestAnimationFrame);
      } else {
        await new Promise(requestAnimationFrame);
      }

      sendBtn.disabled = true;
      let localEngine = null;
      let fullReply = '';
      let streamCompleted = false;

      try {
        localEngine = await createEngineWithProgress();
        engine = localEngine; // set global ref so reset can unload
        const chunks = await localEngine.chat.completions.create({ messages, stream: true });

        // stream and accumulate but DO NOT reveal answer until both stream done and minimum thinking delay passed
        for await (const chunk of chunks) {
          const delta = chunk?.choices?.[0]?.delta?.content || '';
          if (delta) {
            fullReply += delta;
            // enforce cap to prevent runaway
            if (fullReply.length > replyCharCap) {
              fullReply = fullReply.slice(0, replyCharCap) + '\n\n[truncated to fit device limits]';
              break;
            }
            // yield occasionally for UI thread
            if (fullReply.length % 200 === 0) await new Promise(requestAnimationFrame);
          }
        }
        streamCompleted = true;

        // unload model immediately to free memory
        try { await localEngine.unload(); } catch(e) { console.warn('error unloading after stream', e); }
        engine = null;
        localEngine = null;

        hideOverlay();

        // if the model returned something trivial (like "High"), attempt a lightweight direct answer first
        if (isTrivial(fullReply) && retriesLeft > 0) {
          // try a quick direct answer attempt (lightweight)
          const direct = await recoveryDirectAnswer(userText);
          if (direct && !isTrivial(direct)) fullReply = direct;
        }

        // Ensure we have something to show
        if (!fullReply || !fullReply.trim()) {
          fullReply = "I couldn't produce an answer. Try again.";
        }

        // Wait minimum reveal delay 6-20s even if we already have answer.
        const minDelayMs = 6000; // 6s
        const maxDelayMs = 20000; // 20s
        // Choose a smooth randomized delay between 6 and 20 seconds to match your request.
        const revealDelay = Math.floor(Math.random() * (maxDelayMs - minDelayMs + 1)) + minDelayMs;

        // But to keep UX reasonable, if previous messages are many, shorten delay slightly
        const adjustedDelay = Math.min(revealDelay, 12000); // cap to 12s in worst cases (optional safety)

        // Wait until both streamCompleted AND adjustedDelay passed
        const delayPromise = new Promise(resolve => setTimeout(resolve, adjustedDelay));
        await delayPromise; // ensures placeholder visible for requested time

        // Replace thinking placeholder with actual answer (fade-in)
        try {
          // remove placeholder and insert answer node with fade-in
          thinkingEl.remove();
        } catch (e) { /* ignore */ }

        const assistantEl = document.createElement('div');
        assistantEl.className = 'msg assistant fade-in';
        // extract "Answer:" if present to keep output compact
        assistantEl.textContent = extractAnswer(fullReply);
        chat.appendChild(assistantEl);
        requestAnimationFrame(() => { chat.scrollTop = chat.scrollHeight; });

        // persist minimal history (kept zero per low-power)
        history.push({ role: 'user', content: userText }, { role: 'assistant', content: fullReply });
        const maxEntries = HISTORY_TURNS_LOW * 2;
        if (maxEntries > 0 && history.length > maxEntries) history = history.slice(-maxEntries);
        if (maxEntries === 0) history = [];

      } catch (err) {
        console.error('Inference error', err);
        // remove placeholder
        try { thinkingEl.remove(); } catch (e) {}
        // unload and null
        try { if (localEngine) await localEngine.unload(); } catch(e){}
        engine = null;
        localEngine = null;
        hideOverlay();

        // Treat as memory spike; try to reset and retry
        if (retriesLeft > 0) {
          const resetSucceeded = await aggressiveResetAndRetry(userText);
          if (!resetSucceeded) {
            appendMessage('assistant', 'I tried to refresh but failed. Please try again later.');
          }
        } else {
          appendMessage('assistant', 'I had a memory spike and could not recover. Try again later.');
        }
      } finally {
        sendBtn.disabled = false;
      }
    }

    // Recovery direct answer: quick single-line attempt (lightweight)
    async function recoveryDirectAnswer(userText) {
      try {
        const eng = await createEngineWithProgress();
        const sys = "Concise assistant. Provide a single-line direct answer to the user's question. Do NOT include 'Certainty' or steps — just the answer.";
        const messages = [{ role: 'system', content: sys }, { role: 'user', content: userText }];
        const chunks = await eng.chat.completions.create({ messages, stream: true });
        let text = '';
        for await (const chunk of chunks) {
          const delta = chunk?.choices?.[0]?.delta?.content || '';
          if (delta) {
            text += delta;
            if (text.length > REPLY_CHAR_CAP_LOW) {
              text = text.slice(0, REPLY_CHAR_CAP_LOW) + '\n\n[truncated]';
              break;
            }
          }
        }
        try { await eng.unload(); } catch(e){}
        return text.trim();
      } catch (err) {
        console.warn('Direct recovery failed', err);
        return null;
      }
    }

    // queue request (adds to single-run queue)
    function queueRequest(userText){
      if (!userText || !userText.trim()) return;
      appendMessage('user', userText);
      requestQueue.push({ userText });
      processQueue();
    }

    // queue processor
    async function processQueue(){
      if (processing) return;
      processing = true;
      while (requestQueue.length) {
        const req = requestQueue.shift();
        await handleSingleRequest(req.userText);
        await new Promise(resolve => setTimeout(resolve, 120));
      }
      processing = false;
    }

    // UI wiring
    sendBtn.addEventListener('click', () => {
      const txt = userInput.value.trim();
      if (!txt) return;
      userInput.value = '';
      queueRequest(txt);
    });
    userInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') { e.preventDefault(); sendBtn.click(); } });

    // Reset button: clears history and unloads model
    resetBtn.addEventListener('click', async () => {
      history = [];
      chat.innerHTML = '<div class="msg assistant">Memory purged. Ready.</div>';
      requestQueue.length = 0;
      try { if (engine) await engine.unload(); } catch(e) {}
      engine = null;
    });

    // Low-power toggle wiring — default ON if not set
    const lowPowerRaw = loadLowPowerRaw();
    if (lowPowerRaw === null) {
      lowPower = true;
      saveLowPower(true);
    } else {
      lowPower = loadLowPower();
    }
    lowPowerToggle.checked = lowPower;
    lowPowerToggle.addEventListener('change', (e) => {
      lowPower = !!e.target.checked;
      saveLowPower(lowPower);
      appendMessage('assistant', lowPower ? 'Low Power enabled.' : 'Low Power disabled.');
    });

    // Traits editor wiring (kept minimal)
    function openTraits(){ renderTraitsModal(); traitsOverlay.style.display = 'flex'; traitsOverlay.setAttribute('aria-hidden','false'); }
    function closeTraits(){ traitsOverlay.style.display = 'none'; traitsOverlay.setAttribute('aria-hidden','true'); }

    function renderTraitsModal(){
      traitsEditor.innerHTML = '';
      traitsChips.innerHTML = '';
      userTraits.forEach((t, idx) => {
        const chip = document.createElement('div'); chip.className = 'chip'; chip.textContent = t; traitsChips.appendChild(chip);
        const row = document.createElement('div');
        row.style.display = 'flex'; row.style.gap = '8px'; row.style.alignItems = 'center';
        const input = document.createElement('input'); input.value = t; input.placeholder = `Trait ${idx+1}`;
        input.addEventListener('input', () => userTraits[idx] = input.value);
        const rm = document.createElement('button'); rm.className = 'btn'; rm.textContent = 'Remove';
        rm.addEventListener('click', () => { userTraits.splice(idx,1); renderTraitsModal(); });
        row.appendChild(input); row.appendChild(rm);
        traitsEditor.appendChild(row);
      });
      traitsCount.textContent = `${userTraits.length}/${MAX_TRAITS}`;
    }

    addTraitBtn.addEventListener('click', () => {
      if (userTraits.length >= MAX_TRAITS) return;
      userTraits.push('');
      renderTraitsModal();
    });
    saveTraitsBtn.addEventListener('click', () => {
      userTraits = userTraits.map(s => (s || '').trim()).filter(Boolean).slice(0, MAX_TRAITS);
      saveTraits(userTraits);
      closeTraits();
      appendMessage('assistant', 'Traits saved.');
    });
    cancelTraitsBtn.addEventListener('click', () => closeTraits());
    traitsBtn.addEventListener('click', () => openTraits());

    // initial load: small default trait set
    userTraits = loadTraits();
    if (!userTraits || !userTraits.length) {
      userTraits = ['Concise','English'];
      saveTraits(userTraits);
    }

    // focus input
    userInput.focus();
  </script>
</body>
</html>
